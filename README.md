# Overview

I undertook this project during the first half of 2020 as part my final year project while studing Computing for an MEng at Imperial College London. Upon completion of this project and after presenting it to a team of academics, I obtained the mark of 83% (distinguished project). A project report may be found at the following path in this repository: [Report/Final/report.pdf](https://github.com/julambl75/asg-summarisation/blob/master/Report/Final/report.pdf). Moreover, the presentation can be found here: [Presentation/presentation.pdf](https://github.com/julambl75/asg-summarisation/blob/master/Presentation/presentation.pdf).

# Original Project Description

Background:
Text summarisation is a challenging problem in NLP. Many approaches have been proposed which are manly based on Deep learning  methods. But one of the key issues in text summarisation is the understudying of text and the ability to generate grammatically correct sentences using words from the given text. We have recently developed a framework for expressing and learning context-sensitive grammars, called Answer Set Grammars [1]. These are context sensitive grammars that can be used to recognise strings that meet some contextual semantics, and can be learned directly from labelled positive and negative examples of strings.

Project:
This project aims at explore a new way of performing text summarisation by making use of ASG grammars. These grammars will be either manually predefined or learned in a supervised way. This is a completely new project whose scope can be defined together with the student based on his/her interests and skills. Evaluation of the results will be performed by comparing this new approach with methods that are purely based on machine learning.

References:
[1] Mark Law, Alessandra Russo, Elisa Bertino, Krysia Broda, Jorge Lobo, "Representing and Learning Grammars in Answer Set Programming", AAAI 2019: 2919-2928
