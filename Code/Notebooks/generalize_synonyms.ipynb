{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import re\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from parse_concept_net import ParseConceptNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mary went out.\n",
      "it was raining hard.\n",
      "mary went back.\n",
      "she entered quickly.\n"
     ]
    }
   ],
   "source": [
    "# with open('../Samples/mary.txt', 'r') as file:\n",
    "#     story = file.read().lower()\n",
    "story = 'Mary is cycling with her bicycle. She enjoys bicycling on the bike.'\n",
    "\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('mary', 'NN'), ('went', 'VBD'), ('out', 'RB'), ('.', '.')], [('it', 'PRP'), ('was', 'VBD'), ('raining', 'VBG'), ('hard', 'RB'), ('.', '.')], [('mary', 'NN'), ('went', 'VBD'), ('back', 'RB'), ('.', '.')], [('she', 'PRP'), ('entered', 'VBD'), ('quickly', 'RB'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "from pycorenlp import StanfordCoreNLP\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "output = nlp.annotate(story, properties={\n",
    "    'annotators': 'pos',\n",
    "    'outputFormat': 'json'\n",
    "})\n",
    "\n",
    "tokenized = [[(word['word'], word['pos']) for word in sentence['tokens']] for sentence in output['sentences']]\n",
    "print(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "went was 0\n",
      "went entered 0\n",
      "out hard 0\n",
      "out back 0\n",
      "out quickly 0\n",
      "it she 1.15\n",
      "was went 0\n",
      "was went 0\n",
      "was entered 0\n",
      "hard out 0\n",
      "hard back 0\n",
      "hard quickly 0\n",
      "went was 0\n",
      "went entered 0\n",
      "back out 0\n",
      "back hard 0\n",
      "back quickly 0\n",
      "she it 1.15\n",
      "entered went 0\n",
      "entered was 0\n",
      "entered went 0\n",
      "quickly out 0\n",
      "quickly hard 0\n",
      "quickly back 0\n"
     ]
    }
   ],
   "source": [
    "pcn = ParseConceptNet(False)\n",
    "\n",
    "for sentence in tokenized:\n",
    "    for word, pos in sentence:\n",
    "        for other_sentence in tokenized:\n",
    "            for other_word, other_pos in other_sentence:\n",
    "                if word != other_word and pos == other_pos:\n",
    "                    print(word, other_word, pcn.compare_words(word, other_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
