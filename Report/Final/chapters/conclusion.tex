\section{Achievements}

\textsc{SumASG*} is a symbolic system which is able to generate \textit{generic}, \textit{informative} and partially-\textit{abstractive} summaries given a simple story about a paragraph in length.

Internally, it relies on the ASG engine, which is used for both for understanding text and creating summary sentences. This is an \textit{entity level} approach to the task of text summarization, whereby the \textsc{Preprocessor} makes use of the \textit{similarity} between words and sentences, and creates a \textit{text relationship map} to aid in simplifying the given input story.

The core accomplishments of this project are the following:

\begin{itemize}
\item Created a context-free grammar that models the structure of basic English sentences, and can be used both for semantic learning, as well as generating grammatically correct text.
\item Implemented an algorithm that dramatically reduces the complexity in the structure of English sentences, without losing too much information.
\item Implemented an algorithm which uses \textit{similarity} to remove irrelevant sentences from a short story, as well as reduces lexical diversity.
\item Wrote an ASG learning task capable of taking English text and turning it into set of chronologically-ordered \textit{actions}.
\item Developed a set of rules which, given \textit{actions} from a story, allow ASG to generate both \textit{extractive} and \textit{abstractive} summary sentences.
\item Implemented a scoring mechanism prioritizing information density, while taking into account words which may appear frequently in English and can be considered the \textit{topic} of the original text.
\item Created a framework to automatically generate topical short stories to evaluate \textsc{SumASG*}, based on a dataset of words and particular sentence structure.
\end{itemize}

\section{Future Work}

Text summarization is a highly involved task in NLP, bringing together many different fields of study. For this reason, there any many ways in which we could take the overall pipeline forward, the most beneficial of which we shall discuss in what follows. Although the ideas which follow may seem rather involved, it is easy to reduce them to a more manageable task.

\subsection{Better Semantic Understanding}

By way of the \textsc{Preprocessor}, \textsc{SumASG*} is able to transform complex sentence structures into simple ones. Unfortunately, this comes at the cost of removing connectors, as well many auxiliary clauses whose structure \textsc{SumASG} cannot parse.

By doing so we can lose some information, or worse: convey a false meaning due to the intricacy of English semantics. To illustrate this consider the following story, as shown in Figure \ref{fig:complex_summary}.

\begin{figure}[H]\
\begin{subfigure}{\textwidth}
\begin{displayquote}
John and Mary are siblings. Today is Monday 25 May. Unless it rains in London, which is highly likely, John's sister is going running and then buying a brioche feuilletée aux pralines roses tomorrow. However she doesn't know that her favorite bakery doesn't make pastries on Tuesdays.
\end{displayquote}
\caption{Story}
\vspace{\baselineskip}
\end{subfigure}
\begin{subfigure}{\textwidth}
\begin{displayquote}
Unless is rains, Mary is going running and then buying a pastry on Tuesday. However she doesn't know that her favorite bakery doesn't make pastries on that day of the week.
\caption{``Ideal" partially-\textit{abstractive} and \textit{informative} summary}
\end{displayquote}
\end{subfigure}
\caption{Example of a short story with complex semantics}
\label{fig:complex_summary}
\end{figure}

With the way things are currently set up, the \textsc{Preprocessor} might remove the second sentence, getting rid of all useful temporal information from the story. It could also remove the last sentence, which is crucial in the narrative. Finally, it would definitely delete the first two clauses from the third sentence, missing out on an important \textit{nuance}.

Even if all this information had been preserved and passed through to \textsc{SumASG}, it would be unable to understand it in a contextually-aware enough manner. More to the point, the following facts are relevant to create a good summary:

\begin{itemize}
\item John and Mary are siblings, so ``John's sister" refers to Mary.
\item The current day of the week is Monday, so Mary is thinking of going running on a Tuesday.
\item It is probably going to rain on Tuesday, so there is a slim chance Mary will carry out her plans.
\item The bakery where she was planning on getting her pastry not be selling any that day (inference is necessary here).
\end{itemize}

Even though they are essential to comprehend the story, there is also a set of facts that should not appear in the summary:

\begin{itemize}
\item John is Mary's brother.
\item The current date is 25 May.
\item Mary is in London.
\item She is interested specifically in a brioche feuilletée aux pralines roses.
\end{itemize}

In order to understand such a story, we would therefore need to strengthen \textsc{SumASG*} at each step in the pipeline. As well as much better parsing, this would require creating a more complex set of predicates to better capture the meaning in a story. Finally, we would also have the change the \textit{scoring} mechanism, so that it looks for summaries which lose as little meaning as possible from the original story.

\subsection{Longer Stories}

What we would like it to use this mechanism to summarize longer texts, such as newspaper articles or even whole books. Using a supercomputer, we could run a much more advanced and polished version of \textsc{SumASG*} in order to generate a summary of one or more pages in length.

As we have seen, runtime is one of the major bottlenecks of \textsc{SumASG}, which is why \textsc{SumASG*} is limited to very succinct stories. What we would therefore need to do is to carefully reason about the most efficient implementation of our logic program. This could involve separately running \textsc{SumASG*} on each paragraph or page, and then gathering the results together to construct the final summary.

\subsection{Domain-Specific Understanding}

There are many domains where a certain background knowledge is assumed, such as research papers in Computer Science, or scripts for plays. With an enhanced version of \textsc{SumASG*}, we could help authors by automating (or at least partially) their respective tasks of writing abstracts and loglines. A way to accomplish this would be to create a suite of \textit{extensions}, each providing background knowledge to help understand a particular subject.

In the case of reading a paper, the \textit{extension} would include the relevant encyclopedic knowledge translated into logic. By combining this with the information contained in the paper, a machine would be able to understand what the author is talking about.

When it comes to understanding a play, we would need encode into the parsing mechanism the difference in format between reading narrative and dialog (from various characters). By carefully keeping track of the timeline, and using \textit{action} predicates that know who is speaking, we would be able to programmatically learn about the evolution of the characters in the story.