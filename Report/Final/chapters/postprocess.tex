\label{chapter:postprocessing}

\section{Overview}

Once we have obtained potential sentences from ASG to be used in a summary, we now post-process these as explained in Section \ref{sec:summary_creation}. By combining them in different ways, we are able to form summaries. From these, we will retain the highest scoring ones, according to the metric detailed in Section \ref{sec:scoring}. A diagram illustrating these steps is shown below in Figure \ref{fig:postprocess_pipeline}.

\begin{figure}[H]
\centering
\begin{tikzpicture}[node distance=0.55cm, auto]
\node (summary_sentence_1) [inter] {Summary Sentence 1};
\node (summary_sentence_2) [inter, below =of summary_sentence_1] {Summary Sentence 2};
\node (summary_sentence_3) [below =of summary_sentence_2] {...};
\node (summary_sentence_4) [inter, below =of summary_sentence_3] {Summary Sentence n};
\node (post_process_1) [block, right =of summary_sentence_1] {Post-Process};
\node (post_process_2) [block, below =of post_process_1] {Post-Process};
\node (post_process_3) [below =of post_process_2] {...};
\node (post_process_4) [block, below =of post_process_3] {Post-Process};
\node (combine) [block, right =of post_process_2] {Combine};
\node (summary_1) [block, above right =of combine] {Summary 1};
\node (summary_2) [block, below =of summary_1] {Summary 2};
\node (summary_3) [below =of summary_2] {...};
\node (summary_4) [block, below =of summary_3] {Summary m};
\node (score_1) [right =of summary_1] {Score};
\node (score_2) [below =of score_1, right =of summary_2] {Score};
\node (score_3) [below =of score_2] {...};
\node (score_4) [below =of score_3, right =of summary_4] {Score};
\draw [->] (summary_sentence_1) -- (post_process_1);
\draw [->] (summary_sentence_2) -- (post_process_2);
\draw [->] (summary_sentence_4) -- (post_process_4);
\draw [->] (post_process_1) -- (combine);
\draw [->] (post_process_2) -- (combine);
\draw [->] (post_process_4) -- (combine);
\draw [->] (combine) -- (summary_1);
\draw [->] (combine) -- (summary_2);
\draw [->] (combine) -- (summary_4);
\draw [->] (summary_1) -- (score_1);
\draw [->] (summary_2) -- (score_2);
\draw [->] (summary_4) -- (score_4);
\end{tikzpicture}
\caption{Post-Processing / Scoring Steps}
\label{fig:postprocess_pipeline}
\end{figure}

\section{Summary Creation}
\label{sec:summary_creation}

The output of \textsc{SumASG} is a list of sentences, each of which could potentially appear in the final summary.

\subsection{Post-Processing}

\subsubsection{Grammar}

Because \textsc{SumASG} uses the same capitalization for a given word regardless of its position in the sentence, it means that the first word of each sentence will not be capitalized unless it is a proper noun. We therefore need to fix this, as well as remove the space before each full stop.

Compound nouns, whose hyphen was replaced with an underscore for the internal representation of \textsc{SumASG}, also need to be restored to their grammatically-correct form.

In addition, the task of summarization might have created a sentence where an incorrect verb form is used, or possibly the wrong determiner. To amend this we use a tool called \textbf{\href{https://pypi.org/project/language-check/}{language-check}}, which is able to correct phrases like ``they has an dog" to ``they have a dog".

\subsubsection{Complex Nouns}

One of the optimizations done by the \textsc{Preprocessor} was to combine complex nouns such as ``Peter Little" into their camel-case form ``PeterLittle", so that they would be recognized as a single \textit{token} by \textsc{SumASG}. We now need to expand them back to their original form, as this is how it should be written in English.

\subsection{Combining}

Depending on the length of the original story, we envision a different number of sentences to be in the summary, as shown below in Table \ref{tab:summary_length}.

\begin{table}[H]
\centering
\begin{tabular}{@{}llll@{}}
\toprule
Story length   & 1-2 & 3-4 & 5+ \\ \midrule
Summary length & 1   & 2   & 3  \\ \bottomrule
\end{tabular}
\caption{Length of a summary depending on the number of sentences in the story}
\label{tab:summary_length}
\end{table}

Once we have grammatically-correct summary sentences and know how many should be kept for the summary (say $n$), we generate all possible order-preserving combinations of length $n$. For instance, such combinations of length 3 for the list $[0,1,2,3]$ would be the following: $[0,1,2]$, $[0,2,3]$ and $[1,2,3]$.

\section{Scoring}
\label{sec:scoring}

Because we often end up with a large number of combinations at this phase, we need to determine which of them are best and keep only these.

\subsection{Type-Token Ratio}

To this end, we utilize an NLP metric called type-token ratio (TTR), a measure of lexical density. To provide the most informative summaries possible, we want to maximize the density of unique words.

To calculate a summary's TTR, we divide the number of unique words in the summary by the total number of words. We then divide this by number of unique words in the story and multiply it by a constant, in order to get a more consistent range for our scores.

\subsubsection{Ignored Words}

However, we do not want to neglect summaries using the same determiner, proper noun, or the verb ``to be" multiple times, as these are extremely common in English.

In addition, a story might revolve around a given \textit{topic}, which could be a person. Regarding the former, it could also be the case that the \textsc{Preprocessor} had replaced different synonyms of this \textit{topic} with a unique word.

To get around this, what we do is to exclude such words from the summary length and number of unique summary words. This way, we no longer require that these ``common" words be unique in a summary. In the following, we will call the enhanced mechanism \textsc{TTR*}.

In Figure \ref{fig:score_example} is an example which illustrates this metric. The summary with the highest final score is considered to be the best. Moreover, there is a greater difference between the summaries when using \textsc{TTR*}, which takes into account the commonly-used building blocks of the English language.

\begin{figure}[H]
\begin{subfigure}{\textwidth}
\begin{displayquote}
Jonathan was a little boy. He was hungry. Jonathan was eating an apple.
\end{displayquote}
\caption{Story}
\vspace{\baselineskip}
\end{subfigure}
\begin{subfigure}{\textwidth}
\begin{displayquote}
\textbf{A.} \underline{Jonathan} \underline{was} \underline{a} hungry boy. \underline{Jonathan} \underline{was} eating \underline{an} apple.\\
\textbf{B.} \underline{Jonathan} \underline{was} \underline{a} little boy. \underline{Jonathan} \underline{was} \underline{a} hungry boy.
\end{displayquote}
\caption{Possible summaries (underlined words will be ignored by \textsc{TTR*})}
\vspace{\baselineskip}
\end{subfigure}
\begin{subfigure}{\textwidth}
\centering
\begin{tabular}{@{}llllllll@{}}
\toprule
 & Words & Unique words & TTR & Words* & Unique words* & \textsc{TTR*} & Score \\ \midrule
\textbf{A} & 10    & 8            & 0.8 & 4      & 4             & 1    & 38    \\
\textbf{B} & 10    & 6            & 0.6 & 4      & 3             & 0.75 & 28    \\ \bottomrule
\end{tabular}
\caption{Steps for computing the score for each generated summary}
\end{subfigure}
\caption{Score computation (column headers ending with * pertain to \textsc{TTR*})}
\label{fig:score_example}
\end{figure}

\section{Summary Selection}
\label{sec:summary_selection}

\subsection{Proper Nouns}

If a story revolves around a given person and the summary mentions their name, it is preferable for this to be in the first sentence. To put this more clearly, we would like the summary of a biography to introduce the protagonist from the very first sentence. To achieve this, we simply increase the score of every summary starting with a proper noun by a constant.

\subsection{Top Summaries}

With a more complex story (5 or more sentences), it is highly likely that we will end up with a very long list of possible summaries. As there could be a number of very interesting summaries, we do not want to have to choose exactly one.

Instead, we compute 75th percentile over the scores of all generated summaries, and then discard all those whose score falls below this number. We shall call the remaining summaries \textit{top summaries}.

\subsection{Reference Summaries}

Finally, we want to be sure that our framework generates good summaries, and that the scoring works as intended. Therefore, if a story has a \textit{reference summary}, then we should make sure that there exists a similar \textit{top summary}.

In our implementation, we have chosen to use the BLEU score, which measures how closely the output given by a machine matches a text written by a human. If there exists a \textit{top summary} whose BLEU score with one of the \textit{references} is above a certain threshold, then we consider the summarization to be successful.

\section{Example}
\label{sec:postprocess_example}

An example is shown in Figure \ref{fig:postprocess_score_example} for the story of Peter Little.

The first step is to fix the grammar in the \textit{summary sentences} generated by \textsc{SumASG}, which in this case simply involves capitalizing them and removing the space before the full stop. We also need to restore the proper noun ``PeterLittle" to ``Peter Little". After \textit{combining}, we end up with 35 possible summaries.

The next step is \textit{scoring}, where we augment the standard of ignored words with the case-insensitive \textit{topics} set \{"peter", "little"\} in \textsc{TTR*}. This gives us scores in the range $[10,17]$, twenty of which fall below the 75th percentile of 15.0 and never become \textit{top summaries}.

Finally, we compare these \textit{top summaries} to our \textit{reference summaries} for Peter Little, as mentioned in Figure \ref{fig:peter_little}. At least one of them achieves a BLEU score of at least 0.65, confirming they are close enough to \textit{reference summary} \textbf{B}.

\begin{figure}[H]
\begin{subfigure}{\textwidth}
\begin{displayquote}
Peter Little is famous now.\\
The curious little boy was named Peter Little.\\
There was a curious little boy.\\
Peter Little did school always.\\
Peter Little was curious and serious.\\
Peter Little was curious in astronomy.\\
Peter Little was serious in school.
\end{displayquote}
\caption{Post-processed \textit{summary sentences}}
\end{subfigure}
\begin{subfigure}{\textwidth}
\vspace{\baselineskip}
\begin{displayquote}
\textbf{1.} Peter Little is famous now. Peter Little did school always. Peter Little was curious in astronomy.\\
\textbf{2.} Peter Little is famous now. There was a curious little boy. Peter Little did school always.\\
\textbf{3.} Peter Little is famous now. The curious little boy was named Peter Little. Peter Little did school always.\\
\textbf{4.} Peter Little is famous now. Peter Little did school always. Peter Little was curious and serious.\\
...
\end{displayquote}
\caption{\textit{Top summaries}}
\label{fig:top_score_summaries_example}
\end{subfigure}
\begin{subfigure}{\textwidth}
\vspace{\baselineskip}
\centering
\begin{tabular}{@{}lllllll@{}}
\toprule
Summary     & 1    & 2    & 3    & 4    \\ \midrule
Reference A & 0.4  & 0.38 & 0.32 & 0.38  \\
Reference B & 0.66 & 0.58 & 0.49 & 0.63 \\ \bottomrule
\end{tabular}\caption{BLEU scores for \textit{reference summaries} (summary indices as shown in Figure \ref{fig:top_score_summaries_example})}
\end{subfigure}
\caption{Example of \textit{post-processing} then \textit{scoring} for the story of Peter Little}
\label{fig:postprocess_score_example}
\end{figure}