\documentclass[12pt,twoside]{report}
\setcounter{secnumdepth}{3}

\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage[a4paper,width=150mm,top=25mm,bottom=25mm,bindingoffset=6mm]{geometry}
%\usepackage{fancyhdr}
\usepackage[pagestyles]{titlesec}
\usepackage{lipsum}
\usepackage{tikz}
\usepackage{float}
\usepackage{booktabs}
\usepackage{csquotes}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{enumitem}
\usepackage{datetime}
\usepackage{subcaption}
\usepackage[titletoc]{appendix}
\usepackage{titlesec}
\usepackage{enumitem}
\usepackage{color,soul}

\usetikzlibrary{shapes,arrows,trees,positioning}
\tikzstyle{block}=[draw, fill=blue!20, minimum size=2em]

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=blue,
    citecolor=blue
}

% https://tex.stackexchange.com/questions/81942/div-equivalent-to-mod
\makeatletter
\newcommand*{\bdiv}{%
  \nonscript\mskip-\medmuskip\mkern5mu%
  \mathbin{\operator@font div}\penalty900\mkern5mu%
  \nonscript\mskip-\medmuskip
}
\makeatother

% https://tex.stackexchange.com/questions/7032/good-way-to-make-textcircled-numbers
%\newcommand*\circled[1]{\tikz[baseline=(char.base)]{
            %\node[shape=circle,draw,inner sep=2pt] (char) {#1};}}
\newcommand*\circled[1]{\raisebox{.5pt}{\textcircled{\raisebox{-.5pt} {#1}}}}

\renewcommand*\thesection{\arabic{section}}
\newpagestyle{Headings}{
 \sethead
   {Chapter \thechapter: \chaptertitle}
   {}
   {Section \toptitlemarks\thesection: \toptitlemarks\sectiontitle}
   \headrule
 \setfoot{}{\thepage}{}
}
\newpagestyle{PageNum}{
 \setfoot{}{\thepage}{}
}

\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{objective}{Objective}

\newcommand{\tabitem}{~~\llap{\textbullet}~~}
\newcommand{\floor}[1]{\lfloor #1 \rfloor}

\graphicspath{ {media/} }

\newcommand{\reporttitle}{Using Answer Set Grammars For Text Summarization}
\newcommand{\reportauthor}{Julien Amblard}
\newcommand{\supervisor}{Alessandra Russo}
\newcommand{\helper}{David Tuckey}
\newcommand{\secondmarker}{Krysia Broda}
\newcommand{\asgauthor}{Mark Law}
\newcommand{\reporttype}{Individual Project}
\newcommand{\degreetype}{Computing MEng}

\begin{document}

\pagestyle{empty}
\input{title}

\pagenumbering{roman}

\tableofcontents

\titleformat{\chapter}
{\normalfont\huge}{\chaptertitlename{} \thechapter}{20pt}{\bfseries\huge}
\titlespacing*{\chapter}{0pt}{0pt}{40pt}

\chapter{Introduction}
\input{chapters/introduction}
\pagestyle{Headings}
\pagenumbering{arabic}

\chapter{Background}
\input{chapters/background}

\chapter{Contributions}
\input{chapters/contributions}

\chapter{Preprocessor}
\input{chapters/preprocessor}

\chapter{ASG}
\input{chapters/asg}

- Learning is not really learning (ASG never learns how to summarize, we build in rules of feature extraction)
- Describe action predicates as high level semantic descriptor of all possible actions that can happen in sentences

- Maybe formalize mathematically task of summarization (with CFG, BK, E+, E-)
    1. CFG is language, BK is leaf nodes, result is actions
    2. CFG is language, BK is leaf nodes, E is actions, result is summaries
- Appendix with summary generation rules

http://universalteacher.org.uk/lang/engstruct.htm

Ideas:
- use lots of simple/precise rules rather than complicated/general ones to minimize ss
- keep rules as restricted as possible, when concept implemented over time add missing rules
- to avoid having to add grammar constraints try and rely on grammar of input

- reduce search space using mode bias (simple example: 396->16, very complicated example: 9477->1044)

Choice:
1. Simplify using Python script (faster)
2. Make ASG format more complex (new information probably lost in summary anyway)

- for learning actions do one sentence at a time to minimize ss

action(INDEX, VERB, SUBJECT, OBJECT)
summary(VERB, SUBJECT, OBJECT)

verb(INDICATIVE\_FORM, TENSE)
subject(NOUN, DET, ADJ\_OR\_ADV)
object(NOUN, DET, ADJ\_OR\_ADV)
noun(NAME)
adj\_or\_adv(NAME)
det(...)
compound(FIRST, SECOND)  for verbs
conjunct(FIRST, SECOND)  learn both

\chapter{Post-Processing / Scoring}
\input{chapters/postprocess}

\chapter{Evaluation}
\input{chapters/evaluation}

For for each story:
1. Pick predefined lexical field (topic)
2. Pick a single pronoun (p)
3. Pick a single proper noun (pn)
4. For each sentence:
    - Subject: p, pn, or synonym/hyponym/hypernym of topic with optional common adjective for it
    - Verb: verb from same lexical field as topic if possible, otherwise random
    - Object: p, pn, or holonym/meronym of subject with lexical field of currently used common nouns
    

- Compare with NN
    1. Randomize action(...) to generate summary(...) on trained ASG
    2. Train NN to generate same summary(...)
    3. Show framework is sane and expandable (computationally tractable)
    4. Compute Rouge score (PyRouge, must clone repo into project) on ASG and NN

\chapter{Literature Review}
\input{chapters/literature_review}

\begin{appendices}
\titleformat{\chapter}{\normalfont\huge}{\appendixname{} \thechapter.}{20pt}{\bfseries\huge}
\input{appendices/pos}
\input{appendices/asg}
\end{appendices}

%\nocite{*}
\bibliographystyle{vancouver}
\bibliography{references}
\pagestyle{PageNum}

\end{document}