\abstract{
\thispagestyle{plain}
To this day, text summarization remains a largely open-ended problem in Natural Language Processing, and is most often resolved using some form of Machine Learning.

In this project, we aim to resolve the problem for short texts about a paragraph in length, via a novel approach that makes use of Answer Set Grammars. By combining ideas from the fields of logic-based learning, knowledge representation and linguistics, we have created a system that is capable of producing partially \textit{abstractive}, \textit{generic} and \textit{informative} summaries, as well as scoring them by order of pertinence and information density.

The approach chosen for this project relies on a central context-free grammar as its internal representation for a simplified version of the English language. Using Answer Set Programming, the system is able to perform logic-based learning to understand the input text after having preprocessed it, the result of which then goes through a number of summarization logic rules, producing a set of possible summaries.

To verify the soundness of our system and ensure that it behaved as expected, we ran it on a suite of targeted examples during the development phase. When the implementation was complete, we trained a neural network to learn the summarization rules used by our framework. Although neural networks are much more general in terms of what tasks they are capable of, this final evaluation step showed that our approach was both more robust to perturbations in the input, as well as better at detecting the validity of a text.
}