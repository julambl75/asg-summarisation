\abstract{
\thispagestyle{plain}
To this day, text summarization remains a largely open-ended problem in Natural Language Processing, and is most often resolved using some form of Machine Learning.

In this project, we aim to resolve the problem for short texts about a paragraph in length, via a novel approach that makes use of Answer Set Grammars \cite{law_representing_2019}. By combining ideas from the fields of logic-based learning, knowledge representation and linguistics, we have created a system that is capable of producing partially \textit{abstractive}, \textit{generic} and \textit{informative} summaries, as well as scoring them by order of pertinence and information density.

The approach chosen for this project relies on a central context-free grammar as its internal representation for a simplified version of the English language. Using Answer Set Programming, the system is able to perform logic-based learning after preprocessing the input text, the result of which then goes through a number of summarization logic rules, producing a set of possible summaries.

Apart from being developed using a suite of targeted examples, we tried to train an \textit{encoder-decoder} with summaries that were generated by our system, helping to ensure that our approach to summarization made sense.

Overall, we believe that this logic-based approach is promising and has the potential to play a part in the future of automated text summarization.
}